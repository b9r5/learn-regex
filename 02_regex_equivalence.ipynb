{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2870bf4-9a61-4d15-b243-5bb0e495f8f0",
   "metadata": {},
   "source": [
    "## Determining if two regexes are equivalent\n",
    "\n",
    "We will need to define our loss function such that it rewards a prediction\n",
    "$\\hat{y}$ if $y$ and $\\hat{y}$ recognize the same strings. How do we tell\n",
    "whether two regexes recognize the same strings? The classic algorithm\n",
    "has us do the following:\n",
    "\n",
    "1. Convert $y$ and $\\hat{y}$ to NFAs $N$ and $\\hat{N}$.\n",
    "2. Convert $N$ and $\\hat{N}$ to deterministic finite automata (DFAs) $D$ and\n",
    "   $\\hat{D}$.\n",
    "3. Use the table-filling algorithm to determine if the start states of $D$ and\n",
    "   $\\hat{D}$ are equivalent.\n",
    "\n",
    "In this section, we develop the code necessary for steps 2 and 3. Step 1 was\n",
    "already covered when we converted a regex to an NFA for the purpose of\n",
    "generating strings matching the regex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f2aeaa-bfb2-410e-afae-ee229073c78d",
   "metadata": {},
   "source": [
    "### Step 1: Convert regex to NFA\n",
    "\n",
    "Automata-Theory-Constructions already had code for this, which I modified a little (see `regex_to_nfa()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5727e-ff2b-4fd2-9219-dfa516eaeea6",
   "metadata": {},
   "source": [
    "### Step 2: Convert NFA to DFA\n",
    "\n",
    "To convert a nondeterministic finite automaton to a deterministic finite\n",
    "automaton that recognizes the same language, we use the classic subset\n",
    "construction. (A good description of the subset construction can be found in\n",
    "M. Sipser, _Introduction to the Theory of Computation_).\n",
    "\n",
    "We first write a function to compute the set of all NFA states reachable from\n",
    "a given NFA state by following only transitions labeled with $\\epsilon$, the\n",
    "empty string. Recall that $\\epsilon$ is represented by `$` in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c72aa8-6a7f-4f29-a8ea-c16675c4affd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e*(bb+eb)((a+b)(c+b))*\n",
      "de+a+e+(e+b)*+(b+c+d)(b+c+a*)\n",
      "(e*+a+b)(be+b+d)(e*+e*)*\n",
      "(bbb(e+a))*\n",
      "e*\n",
      "(c*(a+c)(c*+b))*\n",
      "((cb)*+c*)(ea+a+e)b*d*\n",
      "e\n",
      "((e+d)*+eeaa)*\n",
      "(d+b)e*(b+a)(c+d)a*\n",
      "['a', '.', 'b', '*']\n",
      "['(', 'a', '.', 'b', ')', '*']\n",
      "['(', 'a', '+', 'b', ')', '*', '.', 'c']\n",
      "['a', 'b', '.']\n",
      "['a', 'b', '.']\n",
      "['a', 'b', '*', '.']\n",
      "['a', 'b', '.', '*']\n",
      "['a', 'b', '+', '*', 'c', '.']\n",
      "ab\n",
      "ab*\n",
      "(ab)*\n",
      "(a+b)*c\n",
      "(<__main__.NFAState object at 0x7f0025cb03d0>, <__main__.NFAState object at 0x7f0025a67880>)\n",
      "(<__main__.NFAState object at 0x7f0025cb0100>, <__main__.NFAState object at 0x7f0025a67af0>)\n",
      "(<__main__.NFAState object at 0x7f0025cb05b0>, <__main__.NFAState object at 0x7f0025a67910>)\n",
      "(<__main__.NFAState object at 0x7f0025cb0100>, <__main__.NFAState object at 0x7f0025a41c30>)\n",
      "regex ab*\n",
      ":abbbbb\n",
      ":abbb\n",
      ":a\n",
      ":a\n",
      ":ab\n",
      ":ab\n",
      ":abb\n",
      ":abbbb\n",
      ":a\n",
      ":a\n",
      "-----\n",
      "regex (ab)*\n",
      ":\n",
      ":\n",
      ":\n",
      ":ab\n",
      ":\n",
      ":\n",
      ":\n",
      ":\n",
      ":ab\n",
      ":\n",
      "-----\n",
      "regex (a+b)*c*\n",
      ":\n",
      ":\n",
      ":\n",
      ":\n",
      ":acc\n",
      ":acc\n",
      ":abc\n",
      ":b\n",
      ":c\n",
      ":\n",
      "-----\n",
      "regex ba+b+c*+c\n",
      ":\n",
      ":ccc\n",
      ":c\n",
      ":b\n",
      ":c\n",
      ":c\n",
      ":c\n",
      ":c\n",
      ":c\n",
      ":c\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "%run 01_regex.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f439cf-c4b0-4bbe-a112-00bcab9822e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_closure(states):\n",
    "    \"\"\"\n",
    "    Compute the set of all states that can be reached from the given states by\n",
    "    following only epsilon ($) transitions. \n",
    "\n",
    "    Args:\n",
    "      states: iterable of NFAState\n",
    "      visited: set of already visited states\n",
    "\n",
    "    Returns:\n",
    "      frozenset of states reachable from states by following only epsilon ($)\n",
    "      transitions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def helper(states, visited):    \n",
    "        for state in states:\n",
    "            if state not in visited:\n",
    "                visited.add(state)\n",
    "                try:\n",
    "                    helper(state.next_state['$'], visited)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "    visited = set()\n",
    "    helper(states, visited)\n",
    "    \n",
    "    return frozenset(visited)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db17acf-d88a-47f2-a32b-0f4ba2370055",
   "metadata": {},
   "source": [
    "To test `epsilon_closure()`, we use a couple of NFAs with $\\epsilon$ transitions. The first is structured like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d56b7d-e6a7-47b0-a65d-8cd6a95d48ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 134.00 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-301 130,-301 130,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"62\" cy=\"-279\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"62\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-192\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;b -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>a&#45;&gt;b</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M55.09,-261.21C50.12,-249.14 43.32,-232.64 37.66,-218.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.83,-217.38 33.78,-209.47 34.35,-220.05 40.83,-217.38\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">系</text>\n",
       "</g>\n",
       "<!-- c -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>c</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-192\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">c</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;c -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>a&#45;&gt;c</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.13,-261.61C74.37,-249.58 81.6,-232.98 87.63,-219.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.98,-220.19 91.76,-209.63 84.56,-217.4 90.98,-220.19\"/>\n",
       "<text text-anchor=\"middle\" x=\"85.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">系</text>\n",
       "</g>\n",
       "<!-- d -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>d</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-105\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">d</text>\n",
       "</g>\n",
       "<!-- b&#45;&gt;d -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>b&#45;&gt;d</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.11,-174.21C39.22,-162.14 46.21,-145.64 52.03,-131.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"55.35,-133.04 56.02,-122.47 48.9,-130.31 55.35,-133.04\"/>\n",
       "<text text-anchor=\"middle\" x=\"51.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">系</text>\n",
       "</g>\n",
       "<!-- c&#45;&gt;d -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>c&#45;&gt;d</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M91.89,-174.21C86.78,-162.14 79.79,-145.64 73.97,-131.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"77.1,-130.31 69.98,-122.47 70.65,-133.04 77.1,-130.31\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">系</text>\n",
       "</g>\n",
       "<!-- e -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>e</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">e</text>\n",
       "</g>\n",
       "<!-- d&#45;&gt;e -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>d&#45;&gt;e</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-86.8C63,-75.16 63,-59.55 63,-46.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5,-46.18 63,-36.18 59.5,-46.18 66.5,-46.18\"/>\n",
       "<text text-anchor=\"middle\" x=\"66.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f0025a67b80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = graphviz.Digraph()\n",
    "dot.node('a')\n",
    "dot.node('b')\n",
    "dot.node('c')\n",
    "dot.node('d')\n",
    "dot.node('e')\n",
    "dot.edge('a', 'b', '系')\n",
    "dot.edge('a', 'c', '系')\n",
    "dot.edge('b', 'd', '系')\n",
    "dot.edge('c', 'd', '系')\n",
    "dot.edge('d', 'e', 'x')\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcdcc96b-46a2-4558-b13a-88e0a4b02099",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = NFAState()\n",
    "b = NFAState()\n",
    "c = NFAState()\n",
    "d = NFAState()\n",
    "e = NFAState()\n",
    "\n",
    "a.next_state['$'] = [b, c]\n",
    "b.next_state['$'] = [d]\n",
    "c.next_state['$'] = [d]\n",
    "d.next_state['x'] = [e]\n",
    "\n",
    "assert epsilon_closure([a]) == {a, b, c, d}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce7c39-c52e-425f-9673-354fa90ebecf",
   "metadata": {},
   "source": [
    "The second graph is structured as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4998185-2783-4958-8a92-825596b73d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"87pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 87.00 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 83,-40 83,4 -4,4\"/>\n",
       "<!-- f -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>f</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">f</text>\n",
       "</g>\n",
       "<!-- f&#45;&gt;f -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>f&#45;&gt;f</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.44,-24.69C63.03,-25.15 72,-22.92 72,-18 72,-14.77 68.14,-12.7 62.49,-11.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.6,-8.29 52.44,-11.31 62.27,-15.28 62.6,-8.29\"/>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">系</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f0025a67ee0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = graphviz.Digraph()\n",
    "dot.edge('f', 'f', '系')\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b36e2a-b0a8-403d-8614-5a42be688520",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = NFAState()\n",
    "f.next_state['$'] = [f]\n",
    "\n",
    "assert epsilon_closure([f]) == {f}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173437aa-8474-4530-8476-9ec2954cab10",
   "metadata": {},
   "source": [
    "Having written a function to compute the $\\epsilon$-closure of a collection of\n",
    "states, we now write a function that converts an NFA to a DFA. This is the\n",
    "well-known subset construction. We find the reachable sets of states using\n",
    "depth first search. Given a set of NFA states constituting a DFA state, and a\n",
    "symbol, the search finds the set of NFA states reachable from the DFA state by\n",
    "following the symbol.\n",
    "\n",
    "Unlike many presentations of the subset construction, we don't compute the\n",
    "power set of NFA states up front, and instead let search find the reachable DFA\n",
    "states for us. We might avoid creating all $2^{|Q|}$ subsets of the NFA states\n",
    "$Q$ in some cases (though in the worst case we will visit $\\Omega(2^{|Q|})$\n",
    "states). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19af953c-2bd6-4e11-b49c-6e6973c6dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A state in a deterministic finite automaton.\n",
    "class DFAState:\n",
    "    def __init__(self, is_accepting):\n",
    "        self.is_accepting = is_accepting\n",
    "        self.next_state = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        lines = ['DFAState ' + str(id(self))]\n",
    "        if self.is_accepting:\n",
    "            lines.append('accepting')\n",
    "        for symbol, state in self.next_state.items():\n",
    "            lines.append(f'\\t{symbol}:\\t{str(id(state))}')\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "# A deterministic finite automaton.\n",
    "class DFA:\n",
    "    def __init__(self, states, start, symbols):\n",
    "        self.states = states\n",
    "        self.start = start\n",
    "        self.symbols = symbols\n",
    "\n",
    "    def __str__(self):\n",
    "        lines = []\n",
    "        for state in self.states:\n",
    "            lines.append('-----')\n",
    "            lines.append(str(id(state)))\n",
    "            if state == self.start:\n",
    "                lines.append('start')\n",
    "            if state.is_accepting:\n",
    "                lines.append('accepting')\n",
    "            for symbol, state in state.next_state.items():\n",
    "                lines.append(f'\\t{symbol}:\\t{str(id(state))}')\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def nfa_to_dfa(start, end, symbols):\n",
    "    \"\"\"\n",
    "    Convert an NFA to a DFA.\n",
    "\n",
    "    Args:\n",
    "      start: the start NFAState\n",
    "      end: the end NFAState\n",
    "      symbols: the alphabet of the NFA\n",
    "\n",
    "    Returns:\n",
    "      a DFA\n",
    "    \"\"\"\n",
    "\n",
    "    def is_accepting(nfa_states):\n",
    "        return any(s == end for s in nfa_states)\n",
    "    \n",
    "    dfa_states = {} # key: set of NFAState, value: DFAState\n",
    "    nfa_states = {} # key: DFAState, value: set of NFAState\n",
    "\n",
    "    closure = epsilon_closure([start])\n",
    "    start_state = DFAState(is_accepting(closure))\n",
    "    dfa_states[closure] = start_state\n",
    "    nfa_states[start_state] = closure\n",
    "\n",
    "    frontier = [start_state]\n",
    "    visited = set()\n",
    "    \n",
    "    while len(frontier) > 0:\n",
    "        state = frontier.pop()\n",
    "\n",
    "        if state in visited:\n",
    "            continue\n",
    "\n",
    "        for symbol in symbols:\n",
    "            # find NFA states reachable from state by following symbol\n",
    "            reachable = set()\n",
    "\n",
    "            for nfa_state in nfa_states[state]:\n",
    "                try:\n",
    "                    reachable.update(nfa_state.next_state[symbol])\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "            reachable = epsilon_closure(reachable)\n",
    "            \n",
    "            if reachable in dfa_states:\n",
    "                next = dfa_states[reachable]\n",
    "            else:\n",
    "                next = DFAState(is_accepting(reachable))\n",
    "                dfa_states[reachable] = next\n",
    "                nfa_states[next] = reachable\n",
    "            \n",
    "            state.next_state[symbol] = next\n",
    "            \n",
    "            if next not in visited:\n",
    "                frontier.append(next)\n",
    "        \n",
    "        visited.add(state)\n",
    "    \n",
    "    return DFA(visited, start_state, symbols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c481c1e-3e86-44d2-98d8-da0eedb0df15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFA for a:\n",
      "-----\n",
      "139638609177248\n",
      "\ta:\t139638609177248\n",
      "-----\n",
      "139638609182240\n",
      "start\n",
      "\ta:\t139638609177392\n",
      "-----\n",
      "139638609177392\n",
      "accepting\n",
      "\ta:\t139638609177248\n",
      "DFA for b*:\n",
      "-----\n",
      "139638609178640\n",
      "accepting\n",
      "\tb:\t139638609178640\n",
      "-----\n",
      "139638609182432\n",
      "start\n",
      "accepting\n",
      "\tb:\t139638609178640\n"
     ]
    }
   ],
   "source": [
    "regexes = ['a', 'b*']\n",
    "symbols = ['a', 'b']\n",
    "\n",
    "for i in range(len(regexes)):\n",
    "    start, end = regex_to_nfa(regexes[i])\n",
    "    dfa = nfa_to_dfa(start, end, symbols[i])\n",
    "    print(f'DFA for {regexes[i]}:')\n",
    "    print(str(dfa))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f9af78-7cdc-4593-a6d0-2e5da84249c7",
   "metadata": {},
   "source": [
    "### Step 3: Determine if two DFAs recognize the same strings\n",
    "\n",
    "We first introduce a disjoint sets data structure based on the union-find algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff3f45c-a133-416e-9c1d-5bd45e14c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A disjoint sets data structure.\n",
    "class UnionFind:\n",
    "    def __init__(self, items):\n",
    "        self.parent = {i: i for i in items}\n",
    "        self.size = {i: 1 for i in items}\n",
    "\n",
    "    def find(self, item):\n",
    "        \"\"\"\n",
    "        Find the representative of an item.\n",
    "\n",
    "        Args:\n",
    "          item: the item for which the representative is wanted\n",
    "\n",
    "        Returns:\n",
    "          the representative of item\n",
    "        \"\"\"\n",
    "        if self.parent[item] == item:\n",
    "            return item\n",
    "        else:\n",
    "            parent = self.find(self.parent[item])\n",
    "            self.parent[item] = parent\n",
    "            return parent\n",
    "\n",
    "    def union(self, item0, item1):\n",
    "        \"\"\"\n",
    "        Merge two items.\n",
    "\n",
    "        Args:\n",
    "          item0 an item\n",
    "          item1 another item (but could also be the same as item0)\n",
    "        \"\"\"\n",
    "        find0 = self.find(item0)\n",
    "        find1 = self.find(item1)\n",
    "        if find0 == find1:\n",
    "            return\n",
    "        if self.size[find0] < self.size[find1]:\n",
    "            find0, find1 = find1, find0\n",
    "        self.parent[find1] = find0\n",
    "        self.size[find0] += self.size[find1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f72f2ab-5ff8-49d4-8ed8-f86674021dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf = UnionFind(range(6))\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(i):\n",
    "        assert uf.find(i) != uf.find(j)\n",
    "\n",
    "uf.union(0, 3)\n",
    "uf.union(1, 4)\n",
    "uf.union(2, 5)\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        assert (uf.find(i) == uf.find(j)) == (i % 3 == j % 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49877bb-c77e-4f24-a1bb-c5259340f21f",
   "metadata": {},
   "source": [
    "Next we write a function that determines if two DFA states $q_0$ and $q_1$ are\n",
    "equivalent, in the sense that for all strings $s$, the state resulting from\n",
    "following $s$ starting at $q_0$ is final if and only if the state resulting\n",
    "from following $s$ starting at $q_1$ is final.\n",
    "\n",
    "The algorithm for this is known as the \"table-filling\" algorithm. A good\n",
    "description can be found in\n",
    "[these lecture notes](https://people.csail.mit.edu/rrw/6.045-2020/lec5-color.pdf)\n",
    "by Ryan Williams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd2b75d1-4e5b-4b02-b5b5-1375cae693aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivalent_states(dfa):\n",
    "    \"\"\"\n",
    "    Compute the equivalent states of a DFA.\n",
    "\n",
    "    Args:\n",
    "      dfa: a DFA\n",
    "\n",
    "    Returns:\n",
    "      a UnionFind such that find(state0) == find(state1) iff state0 and state1\n",
    "      are equivalent\n",
    "    \"\"\"\n",
    "\n",
    "    different = set()\n",
    "\n",
    "    for s0 in dfa.states:\n",
    "        for s1 in dfa.states:\n",
    "            if s0 == s1:\n",
    "                continue\n",
    "            if s0.is_accepting ^ s1.is_accepting:\n",
    "                different.add((s0, s1))\n",
    "                different.add((s1, s0))\n",
    "\n",
    "    stop = False\n",
    "\n",
    "    while not stop:\n",
    "        stop = True\n",
    "        \n",
    "        for s0 in dfa.states:\n",
    "            for s1 in dfa.states:\n",
    "                if s0 == s1 or (s0, s1) in different:\n",
    "                    continue\n",
    "\n",
    "                for symbol in dfa.symbols:\n",
    "                    next0 = s0.next_state[symbol]\n",
    "                    next1 = s1.next_state[symbol]\n",
    "                    if (next0, next1) in different:\n",
    "                        different.add((s0, s1))\n",
    "                        different.add((s1, s0))\n",
    "                        stop = False\n",
    "\n",
    "    result = UnionFind(dfa.states)\n",
    "    for s0 in dfa.states:\n",
    "        for s1 in dfa.states:\n",
    "            if (s0, s1) not in different:\n",
    "                result.union(s0, s1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592a508-45bf-444f-b2ab-68e3502e6ad0",
   "metadata": {},
   "source": [
    "We can use use our function that computes the equivalent states of a DFA to\n",
    "also determine whether two DFAs are equivalent. The idea is to form a \"union\"\n",
    "DFA $D = (Q_0 \\cup Q_1, \\Sigma, \\delta_0 \\cup \\delta_1, -, F_0 \\cup F_1)$,\n",
    "then test whether $q_0$ and $q_1$ are equivalent in $D$. The start state\n",
    "doesn't matter, hence the \"$-$\". The idea comes from\n",
    "[these lecture notes by Ana Bove](https://www.cse.chalmers.se/edu/year/2012/course/TMV026/lec10.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5ebbaeb-f210-46d5-b13b-00a4693ecc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_equivalent_dfas(dfa0, dfa1):\n",
    "    \"\"\"\n",
    "    Determine whether two DFAs have the same language.\n",
    "\n",
    "    Args:\n",
    "      dfa0: a DFA\n",
    "      dfa1: another DFA, which must have states disjoint from dfa0\n",
    "\n",
    "    Returns:\n",
    "      True iff dfa0 and dfa1 have the same language\n",
    "    \"\"\"\n",
    "\n",
    "    if sorted(dfa0.symbols) != sorted(dfa1.symbols):\n",
    "        return False\n",
    "    \n",
    "    states = set(dfa0.states)\n",
    "    states.update(dfa1.states)\n",
    "\n",
    "    # initial state does not matter (it could be anything)\n",
    "    union = DFA(states, dfa0.start, dfa0.symbols)\n",
    "\n",
    "    equiv = equivalent_states(union)\n",
    "\n",
    "    return equiv.find(dfa0.start) == equiv.find(dfa1.start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44af938-fba3-4611-ac13-d5088d9df235",
   "metadata": {},
   "source": [
    "### Wrapping up steps 1-3\n",
    "\n",
    "We finish up with a function to test the equivalence of two regular\n",
    "expressions. First we write a function that extracts the symbols from a regular\n",
    "expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "866c9a88-3e82-4b11-aa49-e42538896de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_to_symbols(regex):\n",
    "    \"\"\"\n",
    "    Given a regular expression, return its symbols.\n",
    "\n",
    "    Args:\n",
    "      regex: a regular expression\n",
    "\n",
    "    Returns:\n",
    "      a string containing the symbols of regex\n",
    "    \"\"\"\n",
    "\n",
    "    # split regex into single characters\n",
    "    chars = set([*regex])\n",
    "\n",
    "    # remove operators and convert to list\n",
    "    nonoperators = list(chars - set(operators))\n",
    "\n",
    "    # sort them\n",
    "    nonoperators.sort()\n",
    "\n",
    "    # join them into a string\n",
    "    return \"\".join(nonoperators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "654b9361-d73b-42f2-ad52-20a48ba6b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexes0 = ['a*', '(a+b)*', 'a']\n",
    "regexes1 = ['a**', '(a*+b*)*', 'b']\n",
    "symbols = ['a', 'ab', 'ab']\n",
    "answer = [True, True, False]\n",
    "\n",
    "for i in range(len(regexes0)):\n",
    "    start0, end0 = regex_to_nfa(regexes0[i])\n",
    "    start1, end1 = regex_to_nfa(regexes1[i])\n",
    "    dfa0 = nfa_to_dfa(start0, end0, regex_to_symbols(regexes0[i]))\n",
    "    dfa1 = nfa_to_dfa(start1, end1, regex_to_symbols(regexes1[i]))\n",
    "    assert are_equivalent_dfas(dfa0, dfa1) == answer[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c24c0-8734-4a52-9f8a-4c80923f0ef6",
   "metadata": {},
   "source": [
    "Now, finally, we write a function that tests the equivalence of two regular\n",
    "expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24d4e817-7ee2-40f6-9fb6-fe772773ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_equivalent_regexes(regex0, regex1):\n",
    "    \"\"\"\n",
    "    Determine whether two regular expressions recognize the same strings.\n",
    "\n",
    "    Args:\n",
    "      regex0: a regex\n",
    "      regex1: also a regex\n",
    "\n",
    "    Returns:\n",
    "      True iff regex0 and regex1 recognize the same strings.\n",
    "    \"\"\"\n",
    "\n",
    "    start0, end0 = regex_to_nfa(regex0)\n",
    "    start1, end1 = regex_to_nfa(regex1)\n",
    "\n",
    "    symbols0 = regex_to_symbols(regex0)\n",
    "    symbols1 = regex_to_symbols(regex0)\n",
    "    \n",
    "    dfa0 = nfa_to_dfa(start0, end0, symbols0)\n",
    "    dfa1 = nfa_to_dfa(start1, end1, symbols1)\n",
    "\n",
    "    return are_equivalent_dfas(dfa0, dfa1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04578669-eb76-44e7-868c-07ffe81d1333",
   "metadata": {},
   "source": [
    "### Appendix: Minimizing DFAs\n",
    "\n",
    "In this section I develop some code to minimize a DFA. I didn't need it for\n",
    "determining the equivalence of regular expressions, but I initially thought I\n",
    "would, and it seemed a shame to delete it.\n",
    "\n",
    "DFA minimization typically requires pruning unreachable states. By\n",
    "construction, the states in the DFAs constructed from NFAs in this notebook are\n",
    "all reachable, so I didn't have to prune them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "727ba254-4d8e-422c-9072-9986132d8051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize(dfa):\n",
    "    equiv = equivalent_states(dfa)\n",
    "\n",
    "    states = {} # map from states of input DFA to states of minimized DFA\n",
    "    \n",
    "    for s in dfa.states:\n",
    "        find = equiv.find(s)\n",
    "\n",
    "        if find not in states:\n",
    "            states[find] = DFAState(find.is_accepting)\n",
    "\n",
    "        states[s] = states[find]\n",
    "\n",
    "    done = set() # states of minimized DFA for which we have next states\n",
    "\n",
    "    for old in dfa.states:\n",
    "        new = states[old]\n",
    "        if new not in done:\n",
    "            new.next_state = {s: states[old.next_state[s]] for s in dfa.symbols}\n",
    "            done.add(new)\n",
    "    \n",
    "    return DFA(done, states[dfa.start], dfa.symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e429d9e2-a767-4b12-9a10-e39b4f516ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFA for b*:\n",
      "-----\n",
      "139638609169952\n",
      "start\n",
      "accepting\n",
      "\tb:\t139638608244176\n",
      "-----\n",
      "139638608244176\n",
      "accepting\n",
      "\tb:\t139638608244176\n",
      "Minimized DFA for b*:\n",
      "-----\n",
      "139638608233712\n",
      "start\n",
      "accepting\n",
      "\tb:\t139638608233712\n",
      "DFA for (a+b)*:\n",
      "-----\n",
      "139638608240384\n",
      "accepting\n",
      "\ta:\t139638608240384\n",
      "\tb:\t139638608247056\n",
      "-----\n",
      "139638608247056\n",
      "accepting\n",
      "\ta:\t139638608240384\n",
      "\tb:\t139638608247056\n",
      "-----\n",
      "139638609178976\n",
      "start\n",
      "accepting\n",
      "\ta:\t139638608240384\n",
      "\tb:\t139638608247056\n",
      "Minimized DFA for (a+b)*:\n",
      "-----\n",
      "139638608246768\n",
      "start\n",
      "accepting\n",
      "\ta:\t139638608246768\n",
      "\tb:\t139638608246768\n",
      "DFA for (a*+b*)*:\n",
      "-----\n",
      "139638608237696\n",
      "accepting\n",
      "\ta:\t139638608236736\n",
      "\tb:\t139638608237696\n",
      "-----\n",
      "139638609169952\n",
      "start\n",
      "accepting\n",
      "\ta:\t139638608236736\n",
      "\tb:\t139638608237696\n",
      "-----\n",
      "139638608236736\n",
      "accepting\n",
      "\ta:\t139638608236736\n",
      "\tb:\t139638608237696\n",
      "Minimized DFA for (a*+b*)*:\n",
      "-----\n",
      "139638608246912\n",
      "start\n",
      "accepting\n",
      "\ta:\t139638608246912\n",
      "\tb:\t139638608246912\n"
     ]
    }
   ],
   "source": [
    "regexes = ['b*', '(a+b)*', '(a*+b*)*']\n",
    "symbols = ['b', 'ab', 'ab']\n",
    "\n",
    "for i in range(len(regexes)):\n",
    "    start, end = regex_to_nfa(regexes[i])\n",
    "    dfa = nfa_to_dfa(start, end, symbols[i])\n",
    "    \n",
    "    print(f'DFA for {regexes[i]}:')\n",
    "    print(str(dfa))\n",
    "\n",
    "    min = minimize(dfa)\n",
    "    print(f'Minimized DFA for {regexes[i]}:')\n",
    "    print(str(min))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
