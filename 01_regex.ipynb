{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e48210-1db5-4977-8872-d61b3c7df211",
   "metadata": {},
   "source": [
    "**Abstract.**\n",
    "I reached the point in my machine learning journey where I understood the basic concepts\n",
    "(backpropagation, regularization, CNNs, RNNs, and transformers), but wanted to dig deeper.\n",
    "The machine learning engineers that I knew suggested that I train a model for a problem I\n",
    "found interesting. I selected learning regular expressions from examples as a toy problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da333ee-3050-478c-99ad-60c0f6d3286f",
   "metadata": {},
   "source": [
    "# Generating training data\n",
    "\n",
    "My plan for generating training data was:\n",
    "\n",
    "1. Generate random regular expressions (regexes).\n",
    "2. For each regex, generate some number of strings matching the regex.\n",
    "3. For training data, let the $(x, y)$ input-output pairs be defined by:\n",
    "   * $y$, a regex\n",
    "   * $x$, a list of strings matching $y$, one per line\n",
    "4. During training, reward if a forward pass through the network, starting with input $x$,\n",
    "   produces an output $\\hat{y}$ such that $y$ and $\\hat{y}$ recognize the same strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fb553-7e3f-4a55-943f-577d0f662224",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1163cf48-21c2-4ec9-94db-ecc0d33acfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351284e8-c38a-4d23-b330-97f172010c2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Automata theory conversions\n",
    "\n",
    "To work with regular expressions and finite automata, I started with\n",
    "[Megha Bose's](https://github.com/Megha-Bose)\n",
    "[Automata Theory Conversions](https://github.com/Megha-Bose/Automata-Theory-Conversions)\n",
    "code. It wasn't licensed, so I asked her permission, and she gave me her\n",
    "permission to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461baa34-a467-4c78-b9c5-d689f037cb0d",
   "metadata": {},
   "source": [
    "## Generating random regexes\n",
    "\n",
    "The following two problems did not seem like toy problems:\n",
    "\n",
    "1. Creating a machine learning system capable of inferring long regexes.\n",
    "2. Createing a machine learning system capable of inferring regexes with deep\n",
    "   nestings of union and Kleene star operations.\n",
    "\n",
    "Because I wanted a toy problem, I needed a way to generate short regexes having\n",
    "shallow nestings. I settled on constructing a random parse tree having a\n",
    "maximum depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b03ac2-c8dd-4b14-86ab-0b0c51b3a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union, Kleene star, concatenation, and grouping operations.\n",
    "# '$' is special character that represents the empty string. \n",
    "# All other characters are considered symbols.\n",
    "operators = ['+', '*', '.', '(', ')']\n",
    "\n",
    "\n",
    "class OpType:\n",
    "    \"\"\"\n",
    "    Constants for regular expression operator types.\n",
    "    \"\"\"\n",
    "    SYMBOL = 1\n",
    "    CONCAT = 2\n",
    "    UNION  = 3\n",
    "    KLEENE = 4\n",
    "\n",
    "\n",
    "class ExpressionNode:\n",
    "    \"\"\"\n",
    "    Node in an expression tree that represents the parse tree for a regular\n",
    "    expression.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, op_type, value=None):\n",
    "        self.op_type = op_type\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Converts the node to a string in infix order, adding a lot of parens.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.op_type == OpType.SYMBOL:\n",
    "            return self.value\n",
    "        elif self.op_type == OpType.CONCAT:\n",
    "            left = f'({self.left})' if self.left.op_type == OpType.UNION else str(self.left)\n",
    "            right = f'({self.right})' if self.right.op_type == OpType.UNION else str(self.right)\n",
    "            return left + right\n",
    "        elif self.op_type == OpType.UNION:\n",
    "            return f'{self.left}+{self.right}'\n",
    "        elif self.op_type == OpType.KLEENE:\n",
    "            if self.left.op_type == OpType.KLEENE:\n",
    "                return str(self.left)\n",
    "            elif self.left.op_type == OpType.SYMBOL:\n",
    "                return str(self.left) + '*'\n",
    "            else:\n",
    "                return f'({self.left})*'\n",
    "        else:\n",
    "            raise Exception(f'unknown op type {self.op_type}')\n",
    "\n",
    "\n",
    "def random_regex(max_depth=5, symbols=\"abcde\", recurse_prob=0.95):\n",
    "    \"\"\"\n",
    "    Generates a random regular expression.\n",
    "\n",
    "    Args:\n",
    "      max_depth: maximum depth of the parse tree\n",
    "      symbols: allowed characters of the regular expression; must not contain \n",
    "               '$' nor any operator\n",
    "      recurse_prob: probability that this method is invoked recursively\n",
    "\n",
    "    Returns:\n",
    "      expression tree representing the regular expression\n",
    "    \"\"\"\n",
    "\n",
    "    can_recurse = max_depth > 1 and random.random() < recurse_prob\n",
    "\n",
    "    op_type = random.randint(2, 4) if can_recurse else OpType.SYMBOL\n",
    "    \n",
    "    node = ExpressionNode(op_type)\n",
    "\n",
    "    if op_type == OpType.SYMBOL:\n",
    "        node.value = random.choice(symbols)\n",
    "    else:\n",
    "        node.left = random_regex(max_depth-1, symbols, recurse_prob)\n",
    "        if op_type == OpType.CONCAT or op_type == OpType.UNION:\n",
    "            node.right = random_regex(max_depth-1, symbols, recurse_prob)\n",
    "        \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93458bed-1747-4a4f-9185-69a9d707ae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e*(bb+eb)((a+b)(c+b))*\n",
      "de+a+e+(e+b)*+(b+c+d)(b+c+a*)\n",
      "(e*+a+b)(be+b+d)(e*+e*)*\n",
      "(bbb(e+a))*\n",
      "e*\n",
      "(c*(a+c)(c*+b))*\n",
      "((cb)*+c*)(ea+a+e)b*d*\n",
      "e\n",
      "((e+d)*+eeaa)*\n",
      "(d+b)e*(b+a)(c+d)a*\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(random_regex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e046e-9e9c-44fb-93ba-e8cc9ca5a1db",
   "metadata": {},
   "source": [
    "We've now generated random regexes, so we turn to generating strings matching a single regex.\n",
    "\n",
    "## Generating strings matching a regex\n",
    "\n",
    "To generate strings matching a regex, I first converted the regex into a non-deterministic\n",
    "finite automaton (NFA), then followed random paths through the NFA from an initial node to\n",
    "a terminal node.\n",
    "\n",
    "### Step 1: rewrite regex (add concatenation, convert to postfix)\n",
    "\n",
    "The first step in computing a regex to an NFA is to parse it. For this, it's useful to\n",
    "rewrite the regex in a couple of ways:\n",
    "\n",
    "1. Add concatenation symbols for convenience.\n",
    "2. Convert the regex to postfix order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9808c69c-0be5-4c58-829d-fe21d636bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_concat(regex):\n",
    "    \"\"\"\n",
    "    Adds concatenation operators ('.') to the input regex for convenience.\n",
    "    \n",
    "    Args:\n",
    "      regex: a string representing the regular expression\n",
    "      \n",
    "    Returns:\n",
    "      a list representing the regular expression with added concatenation operators\n",
    "    \"\"\"\n",
    "    \n",
    "    global non_symbols\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(regex) - 1):\n",
    "        result.append(regex[i])\n",
    "        if regex[i] not in operators:\n",
    "            if regex[i + 1] not in operators or regex[i + 1] == '(':\n",
    "                result += '.'\n",
    "        elif regex[i] == ')' and regex[i + 1] == '(':\n",
    "            result += '.'\n",
    "        elif regex[i] == '*' and regex[i + 1] == '(':\n",
    "            result += '.'\n",
    "        elif regex[i] == '*' and regex[i + 1] not in operators:\n",
    "            result += '.'\n",
    "        elif regex[i] == ')' and regex[i + 1] not in operators:\n",
    "            result += '.'\n",
    "\n",
    "    result += regex[-1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30138fea-f04c-4f29-ab4b-71b5e2ab7557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', '.', 'b', '*']\n",
      "['(', 'a', '.', 'b', ')', '*']\n",
      "['(', 'a', '+', 'b', ')', '*', '.', 'c']\n"
     ]
    }
   ],
   "source": [
    "print(add_concat(\"ab*\"))\n",
    "print(add_concat(\"(ab)*\"))\n",
    "print(add_concat(\"(a+b)*c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0112db8a-8d38-4582-992a-8ebf17414237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_precedence(a, b):\n",
    "    \"\"\"\n",
    "    Compares the precendence of the +, ., and * operators.\n",
    "    \n",
    "    Args:\n",
    "      a: the first operator\n",
    "      b: the second operator\n",
    "      \n",
    "    Returns:\n",
    "      True iff a has precedence over b\n",
    "    \"\"\"\n",
    "    p = [\"+\", \".\", \"*\"]\n",
    "    return p.index(a) > p.index(b)\n",
    "\n",
    "\n",
    "def compute_postfix(regexp):\n",
    "    \"\"\"\n",
    "    Converts an input regex to postfix order.\n",
    "    \n",
    "    Args:\n",
    "      regex: list of regex operators and symbols\n",
    "      \n",
    "    Returns:\n",
    "      list representing the regular expression in postfix order\n",
    "    \"\"\"\n",
    "    \n",
    "    stack = []\n",
    "    result = []\n",
    "\n",
    "    for c in regexp:\n",
    "        if c not in operators or c == \"*\":\n",
    "            result += c\n",
    "        elif c == \")\":\n",
    "            while len(stack) > 0 and stack[-1] != \"(\":\n",
    "                result += stack.pop()\n",
    "            stack.pop()\n",
    "        elif c == \"(\":\n",
    "            stack.append(c)\n",
    "        elif len(stack) == 0 or stack[-1] == \"(\" or compare_precedence(c, stack[-1]):\n",
    "            stack.append(c)\n",
    "        else:\n",
    "            while len(stack) > 0 and stack[-1] != \"(\" and not compare_precedence(c, stack[-1]):\n",
    "                result += stack.pop()\n",
    "            stack.append(c)\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        result += stack.pop()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa53c8e8-dc4f-4012-8911-60bbe29a83e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', '.']\n",
      "['a', 'b', '.']\n",
      "['a', 'b', '*', '.']\n",
      "['a', 'b', '.', '*']\n",
      "['a', 'b', '+', '*', 'c', '.']\n"
     ]
    }
   ],
   "source": [
    "print(compute_postfix(['a', '.', 'b']))\n",
    "print(compute_postfix(['(', 'a', '.', 'b', ')']))\n",
    "print(compute_postfix(['a', '.', 'b', '*']))\n",
    "print(compute_postfix(['(', 'a', '.', 'b', ')', '*']))\n",
    "print(compute_postfix(['(', 'a', '+', 'b', ')', '*', '.', 'c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56116bc1-6fff-4c3b-bcb8-e9c8dfc06a3c",
   "metadata": {},
   "source": [
    "### Step 2: create expression tree from regex\n",
    "\n",
    "Having converted the regex to postfix order, we create an expression tree from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3624189-0cd8-4328-a3c3-531e44d334a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expression_tree(regexp):\n",
    "    \"\"\"\n",
    "    Makes an expression tree from a regex.\n",
    "    \n",
    "    Args:\n",
    "      regex: a regular expression in postfix form\n",
    "      \n",
    "    Returns:\n",
    "      an expression tree\n",
    "    \"\"\"\n",
    "    \n",
    "    stack = []\n",
    "\n",
    "    for c in regexp:\n",
    "        if c == \"+\":\n",
    "            z = ExpressionNode(OpType.UNION)\n",
    "            z.right = stack.pop()\n",
    "            z.left = stack.pop()\n",
    "            stack.append(z)\n",
    "        elif c == \".\":\n",
    "            z = ExpressionNode(OpType.CONCAT)\n",
    "            z.right = stack.pop()\n",
    "            z.left = stack.pop()\n",
    "            stack.append(z)\n",
    "        elif c == \"*\":\n",
    "            z = ExpressionNode(OpType.KLEENE)\n",
    "            z.left = stack.pop() \n",
    "            stack.append(z)\n",
    "        elif c == \"(\" or c == \")\":\n",
    "            continue  # just for safety; our input does not contain parens\n",
    "        else:\n",
    "            stack.append(ExpressionNode(OpType.SYMBOL, c))\n",
    "    return stack[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d82de9e-8028-433b-944a-cbee0446a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab\n",
      "ab*\n",
      "(ab)*\n",
      "(a+b)*c\n"
     ]
    }
   ],
   "source": [
    "print(make_expression_tree(['a', 'b', '.']))\n",
    "print(make_expression_tree(['a', 'b', '*', '.']))\n",
    "print(make_expression_tree(['a', 'b', '.', '*']))\n",
    "print(make_expression_tree(['a', 'b', '+', '*', 'c', '.']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f2bbc-a626-4f65-9215-20662287258c",
   "metadata": {},
   "source": [
    "### Step 3: convert expression tree into a NFA\n",
    "\n",
    "Having parsed the regex into a tree, we now convert the tree into a nondeterministic finite automaton (NFA).\n",
    "\n",
    "We use `$` to denote the empty string; in textbooks $\\epsilon$ normally denotes the empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54818dcf-c653-421e-affe-459ec12fa6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFAState:\n",
    "    def __init__(self):\n",
    "        self.next_state = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        lines = ['NFAState ' + str(id(self))]\n",
    "        for symbol, states in self.next_state.items():\n",
    "            for state in states: \n",
    "                lines.append(f'\\t{symbol}:\\t{str(id(state))}')\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "def compute_nfa(node):\n",
    "    \"\"\"\n",
    "    Compute the NFA for an ExpressionNode.\n",
    "    \n",
    "    Args:\n",
    "      node: an ExpressionNode\n",
    "      \n",
    "    Returns:\n",
    "      the start and end NFAState for node\n",
    "    \"\"\"\n",
    "    \n",
    "    if node.op_type == OpType.CONCAT:\n",
    "        left_nfa  = compute_nfa(node.left)\n",
    "        right_nfa = compute_nfa(node.right)\n",
    "\n",
    "        # '$' represents the empty string (usually denoted epsilon)\n",
    "        left_nfa[1].next_state['$'] = [right_nfa[0]]\n",
    "        return left_nfa[0], right_nfa[1]\n",
    "\n",
    "    elif node.op_type == OpType.UNION:\n",
    "        start = NFAState()\n",
    "        end = NFAState()\n",
    "\n",
    "        first_nfa = compute_nfa(node.left)\n",
    "        second_nfa = compute_nfa(node.right)\n",
    "\n",
    "        start.next_state['$'] = [first_nfa[0], second_nfa[0]]\n",
    "        first_nfa[1].next_state['$'] = [end]\n",
    "        second_nfa[1].next_state['$'] = [end]\n",
    "\n",
    "        return start, end\n",
    "\n",
    "    elif node.op_type == OpType.KLEENE:\n",
    "        start = NFAState()\n",
    "        end = NFAState()\n",
    "\n",
    "        starred_nfa = compute_nfa(node.left)\n",
    "\n",
    "        start.next_state['$'] = [starred_nfa[0], end]\n",
    "        starred_nfa[1].next_state['$'] = [starred_nfa[0], end]\n",
    "        \n",
    "        return start, end\n",
    "\n",
    "    elif node.op_type == OpType.SYMBOL:\n",
    "        start = NFAState()\n",
    "        end = NFAState()\n",
    "        start.next_state[node.value] = [end]\n",
    "        return start, end\n",
    "    \n",
    "    else:\n",
    "        raise Exception(f'unknown op type {node.op_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31743a-2329-4555-afe3-dd1a3953cee9",
   "metadata": {},
   "source": [
    "### Putting steps 1-3 together\n",
    "\n",
    "We now wrap up steps 1-3 in a function that takes a regex as argument and returns an NFA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22164b18-2640-4e4e-bb79-2028db267d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_to_nfa(regex):\n",
    "    \"\"\"\n",
    "    Compute the NFA for a regular expression.\n",
    "    \n",
    "    Args:\n",
    "      regex: a regular expression\n",
    "    \n",
    "    Returns:\n",
    "      the start and end NFAState\n",
    "    \"\"\"\n",
    "    \n",
    "    concat = add_concat(regex)\n",
    "    postfix = compute_postfix(concat)\n",
    "    tree = make_expression_tree(postfix)\n",
    "    start, end = compute_nfa(tree)\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47da7913-bbfb-412f-9245-5bee87dbef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<__main__.NFAState object at 0x7f949c365c30>, <__main__.NFAState object at 0x7f949c3651b0>)\n",
      "(<__main__.NFAState object at 0x7f949c366f50>, <__main__.NFAState object at 0x7f949c365ae0>)\n",
      "(<__main__.NFAState object at 0x7f949c365270>, <__main__.NFAState object at 0x7f949c3670d0>)\n",
      "(<__main__.NFAState object at 0x7f949c365fc0>, <__main__.NFAState object at 0x7f949c365c90>)\n"
     ]
    }
   ],
   "source": [
    "print(regex_to_nfa(\"ab*\"))\n",
    "print(regex_to_nfa(\"(ab)*\"))\n",
    "print(regex_to_nfa(\"(a+b)*c\"))\n",
    "print(regex_to_nfa(str(random_regex(6))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41cb82f-69c3-4e74-9f7f-c36cbd7e4164",
   "metadata": {},
   "source": [
    "### Step 4: random paths through an NFA\n",
    "\n",
    "Starting with an NFA, we've generated a regex. The next step is to generate strings matching\n",
    "the regex from the NFA. To do that, we follow a random path through the NFA from the initial\n",
    "node. We build the sequence of edge labels we see along the path traveled so far. When we reach\n",
    "the terminal node, we output the edge labels we saw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c306a13c-f61f-4ace-9680-1036956ef8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfa_path(start, end, max_steps):\n",
    "    \"\"\"\n",
    "    Follow a random path through an NFA, accumulating edge labels.\n",
    "    \n",
    "    Args:\n",
    "      start: start NFAState\n",
    "      end: end NFAState\n",
    "      \n",
    "    returns:\n",
    "      ':' followed by edge labels, or an empty string if no path\n",
    "      to end state of at most max_steps steps was found\n",
    "    \"\"\"\n",
    "    \n",
    "    step = 0\n",
    "    state = start\n",
    "    found_path = False\n",
    "    labels = []\n",
    "    \n",
    "    while step < max_steps:\n",
    "        if state == end:\n",
    "            found_path = True\n",
    "            break\n",
    "            \n",
    "        # select random label\n",
    "        i = random.randint(0, len(state.next_state) - 1)\n",
    "        label = list(state.next_state)[i]\n",
    "        if label != '$':\n",
    "            labels.append(label)\n",
    "        \n",
    "        # select random next state\n",
    "        i = random.randint(0, len(state.next_state[label]) - 1)\n",
    "        state = state.next_state[label][i]\n",
    "    \n",
    "    if found_path:\n",
    "        return ':' + ''.join(labels)\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b81835b0-45f5-4607-9903-5326c1631bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regex ab*\n",
      ":abbbbb\n",
      ":abbb\n",
      ":a\n",
      ":a\n",
      ":ab\n",
      ":ab\n",
      ":abb\n",
      ":abbbb\n",
      ":a\n",
      ":a\n",
      "-----\n",
      "regex (ab)*\n",
      ":\n",
      ":\n",
      ":\n",
      ":ab\n",
      ":\n",
      ":\n",
      ":\n",
      ":\n",
      ":ab\n",
      ":\n",
      "-----\n",
      "regex (a+b)*c*\n",
      ":\n",
      ":\n",
      ":\n",
      ":\n",
      ":acc\n",
      ":acc\n",
      ":abc\n",
      ":b\n",
      ":c\n",
      ":\n",
      "-----\n",
      "regex ba+b+c*+c\n",
      ":\n",
      ":ccc\n",
      ":c\n",
      ":b\n",
      ":c\n",
      ":c\n",
      ":c\n",
      ":c\n",
      ":c\n",
      ":c\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "regexes = ['ab*', '(ab)*', '(a+b)*c*', str(random_regex(4, 'abc'))]\n",
    "\n",
    "for regex in regexes:\n",
    "    print('regex', regex)\n",
    "    start, end = regex_to_nfa(regex)\n",
    "    for i in range(0, 10):\n",
    "        print(nfa_path(start, end, 8))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2417d60-a1ae-4395-a055-8f4d639d80c6",
   "metadata": {},
   "source": [
    "### Step 5: create training data\n",
    "\n",
    "We now generate training data as files in a data directory. I decided to start\n",
    "simple, with regexes having a maximum depth of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f252ce8a-234f-4ac0-981d-adb720eeba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(files, examples_per_file,\n",
    "                         max_depth=4, symbols=\"abcdefghijklmnop\",\n",
    "                         recurse_prob=0.95):\n",
    "    \"\"\"\n",
    "    Generate training data. Each file contains a regex and some strings\n",
    "    matching the regex.\n",
    "\n",
    "    Args:\n",
    "      files: number of files to create\n",
    "      examples_per_file: number of matching strings per file\n",
    "      max_depth: see random_regex()\n",
    "      symbols: see random_regex()\n",
    "      recurse_prob: see random_regex()\n",
    "    \"\"\"\n",
    "    \n",
    "    os.mkdir('data')\n",
    "    \n",
    "    for i in range(files):\n",
    "        with open(f'data/{i:06}.regex', 'x') as file:\n",
    "            regex = str(random_regex(max_depth=max_depth, symbols=symbols,\n",
    "                                     recurse_prob=recurse_prob))\n",
    "\n",
    "            start, end = regex_to_nfa(regex)\n",
    "\n",
    "            # choose a reasonable number of steps through the NFA.\n",
    "            # empirically allowing max_steps = 4 * examples is enough\n",
    "            # to frequently reach an accepting state\n",
    "            max_steps = examples_per_file * 4\n",
    "            \n",
    "            for i in range(examples_per_file):\n",
    "                path = ''\n",
    "                # repeat until we find a path to an accepting state:\n",
    "                while not path.startswith(':'):\n",
    "                    path = nfa_path(start, end, max_steps)\n",
    "\n",
    "                file.write(f'{path}\\n')\n",
    "\n",
    "            # indicate that no more examples follow with the prompt '>'\n",
    "            file.write('>\\n')\n",
    "\n",
    "            # finally, write the regex\n",
    "            file.write(f'{regex}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55632237-7fa6-4fb7-89d4-ed2ae8dfaf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1746ae9-0df8-4e97-b81c-41af1f57bb93",
   "metadata": {},
   "source": [
    "I decided to generate one million regexes worth of training data. Empirically,\n",
    "I found that when using the function `nfa_path()`, there were at most 900\n",
    "unique strings generated per regex. It seemed reasonable to generate some\n",
    "repeats, both to allow training to guess the structure of the regex, and to\n",
    "allow `nfa_path()` to cover the NFA's structure. So I chose to generate 10,000\n",
    "examples per file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a524a5fb-11b4-4166-95f0-c84d9753817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = 1_000_000\n",
    "examples_per_file = 10_000\n",
    "create_training_data(files, examples_per_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f109782-d655-4737-8303-122539c42181",
   "metadata": {},
   "source": [
    "And there we have it -- one million training files!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b234492b-1c1e-48be-b102-0fd76a926139",
   "metadata": {},
   "source": [
    "## Determining if two regexes are equivalent\n",
    "\n",
    "We will need to define our loss function such that it rewards a prediction\n",
    "$\\hat{y}$ if $y$ and $\\hat{y}$ recognize the same strings. How do we tell\n",
    "whether two regexes recognize the same strings? The classic algorithm\n",
    "has us do the following:\n",
    "\n",
    "1. Convert $y$ and $\\hat{y}$ to NFAs $N$ and $\\hat{N}$.\n",
    "2. Convert $N$ and $\\hat{N}$ to deterministic finite automata (DFAs) $D$ and\n",
    "   $\\hat{D}$.\n",
    "3. Minimize $D$ and $\\hat{D}$, obtaining DFAs $M$ and $\\hat{M}$.\n",
    "4. Check whether $M$ and $\\hat{M}$ are identical modulo renaming of states.\n",
    "\n",
    "In this section, we develop the code necessary for steps 2-4. Step 1 was\n",
    "already covered when we converted a regex to an NFA for the purpose of\n",
    "generating strings matching the regex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3dc3e3-dc0e-4425-b067-c63da5784e21",
   "metadata": {},
   "source": [
    "### Step 1: convert regex to NFA\n",
    "\n",
    "Automata-Theory-Constructions already had code for this, which I modified a little (see `regex_to_nfa()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e7c4f-053f-45b1-a6e6-ae26146545eb",
   "metadata": {},
   "source": [
    "### Step 2: NFA to DFA\n",
    "\n",
    "This is a classic subset construction algorithm from the theory of finiste\n",
    "automata. We first write a function to compute the set of all states reachable\n",
    "from a given state by following only transitions labeled with $\\epsilon$ (`$`\n",
    "in our code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d6b8ce0-76c9-4810-94a5-dda9ff023c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_closure(states):\n",
    "    \"\"\"\n",
    "    Compute the set of all states that can be reached from the given states by\n",
    "    following only epsilon ($) transitions. \n",
    "\n",
    "    Args:\n",
    "      states: iterable of NFAState\n",
    "      visited: set of already visited states\n",
    "\n",
    "    Returns:\n",
    "      frozenset of states reachable from states by following only epsilon ($)\n",
    "      transitions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def helper(states, visited):    \n",
    "        for state in states:\n",
    "            if state not in visited:\n",
    "                try:\n",
    "                    helper(state.next_state['$'], visited)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                visited.add(state)\n",
    "\n",
    "    visited = set()\n",
    "    helper(states, visited)\n",
    "    \n",
    "    return frozenset(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79905525-20e6-4355-a443-b3063febb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up transitions as follows.\n",
    "# all transitions are epsilon transitions except d -> e\n",
    "# a -> b -> d -> e\n",
    "# |         ^\n",
    "# +--> c ---+\n",
    "def test_epsilon_closure():\n",
    "    a = NFAState()\n",
    "    b = NFAState()\n",
    "    c = NFAState()\n",
    "    d = NFAState()\n",
    "    e = NFAState()\n",
    "\n",
    "    a.next_state['$'] = [b, c]\n",
    "    b.next_state['$'] = [d]\n",
    "    c.next_state['$'] = [d]\n",
    "    d.next_state['x'] = [e]\n",
    "    \n",
    "    assert epsilon_closure([a]) == {a, b, c, d}\n",
    "\n",
    "test_epsilon_closure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed122892-24a5-40ef-99d5-2dd3a620f1c1",
   "metadata": {},
   "source": [
    "Next we write a function that converts an NFA to a DFA. The function uses\n",
    "depth-first search. Given a set of NFA states constituting a DFA state, and a\n",
    "symbol, the search finds the NFA states reachable from the DFA state by\n",
    "following the symbol.\n",
    "\n",
    "This is similar to the classic subset construction, except that we don't\n",
    "compute the power set of NFA states up front, and instead let search find the\n",
    "reachable DFA states for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4f2e21e-f414-4876-bf92-3cf95bb0d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFAState:\n",
    "    def __init__(self, nfa_states, end_nfa_state):\n",
    "        self.nfa_states = nfa_states\n",
    "        self.next_state = {}\n",
    "        self.is_accepting = any(end_nfa_state == s for s in nfa_states)\n",
    "\n",
    "    def __str__(self):\n",
    "        lines = ['DFAState ' + str(id(self))]\n",
    "        if self.is_accepting:\n",
    "            lines.append('accepting')\n",
    "        for symbol, state in self.next_state.items():\n",
    "            lines.append(f'\\t{symbol}:\\t{str(id(state))}')\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "class DFA:\n",
    "    def __init__(self, states, start):\n",
    "        self.states = states\n",
    "        self.start = start\n",
    "\n",
    "    def __str__(self):\n",
    "        lines = []\n",
    "        for state in self.states:\n",
    "            lines.append('-----')\n",
    "            if state == self.start:\n",
    "                lines.append('start state')\n",
    "            if len(state.nfa_states) == 0:\n",
    "                lines.append('empty state')\n",
    "            lines.append(str(state))\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def nfa_to_dfa(start, end, symbols):\n",
    "    \"\"\"\n",
    "    Convert an NFA to a DFA.\n",
    "\n",
    "    Args:\n",
    "      start: the start NFAState\n",
    "      end: the end NFAState\n",
    "      symbols: the alphabet of the NFA\n",
    "\n",
    "    Returns:\n",
    "      a DFA\n",
    "    \"\"\"\n",
    "\n",
    "    start_state = DFAState(epsilon_closure([start]), end)  \n",
    "    frontier = [start_state]\n",
    "    visited = set()\n",
    "    dfa_states = {} # key: set of NFAState, value: DFAState\n",
    "    \n",
    "    while len(frontier) > 0:\n",
    "        state = frontier.pop()\n",
    "\n",
    "        if state in visited:\n",
    "            continue\n",
    "\n",
    "        for symbol in symbols:\n",
    "            # find NFA states reachable from state by following symbol\n",
    "            reachable = set()\n",
    "\n",
    "            for nfa_state in state.nfa_states:\n",
    "                try:\n",
    "                    reachable.update(nfa_state.next_state[symbol])\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "            reachable = epsilon_closure(reachable)\n",
    "            \n",
    "            if reachable in dfa_states:\n",
    "                next = dfa_states[reachable]\n",
    "            else:\n",
    "                next = DFAState(reachable, end)\n",
    "                dfa_states[reachable] = next\n",
    "            \n",
    "            state.next_state[symbol] = next\n",
    "            \n",
    "            if next not in visited:\n",
    "                frontier.append(next)\n",
    "        \n",
    "        visited.add(state)\n",
    "    \n",
    "    return DFA(visited, start_state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4c33c1e-f348-4676-8402-0df05629d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFA for a:\n",
      "-----\n",
      "start state\n",
      "DFAState 140274275416192\n",
      "\ta:\t140274278024624\n",
      "-----\n",
      "DFAState 140274278024624\n",
      "accepting\n",
      "\ta:\t140274278024768\n",
      "-----\n",
      "empty state\n",
      "DFAState 140274278024768\n",
      "\ta:\t140274278024768\n",
      "DFA for b*:\n",
      "-----\n",
      "start state\n",
      "DFAState 140274275417344\n",
      "accepting\n",
      "\tb:\t140274276305600\n",
      "-----\n",
      "DFAState 140274276305600\n",
      "accepting\n",
      "\tb:\t140274276305600\n"
     ]
    }
   ],
   "source": [
    "regexes = ['a', 'b*']\n",
    "symbols = ['a', 'b']\n",
    "\n",
    "for i in range(len(regexes)):\n",
    "    start, end = regex_to_nfa(regexes[i])\n",
    "    dfa = nfa_to_dfa(start, end, symbols[i])\n",
    "    print(f'DFA for {regexes[i]}:')\n",
    "    print(str(dfa))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520fefa-ebe5-4d76-b7af-b20c7f6ed5a7",
   "metadata": {},
   "source": [
    "### Step 3: minimize DFA\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9824c045-067c-4ac8-8359-5202758b70d0",
   "metadata": {},
   "source": [
    "### Step 4: check whether DFAs are identical\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
